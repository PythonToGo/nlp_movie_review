{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPZ3sglQbFgyjCSPN+anei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PythonToGo/nlp_movie_review/blob/main/NLP_test_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Processing"
      ],
      "metadata": {
        "id": "8UH9B4NeR0nv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfkjAhAYMK-2",
        "outputId": "69c1ab37-17cc-4096-c96e-575e146b1151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: kss in /usr/local/lib/python3.10/dist-packages (4.5.4)\n",
            "Requirement already satisfied: emoji==1.2.0 in /usr/local/lib/python3.10/dist-packages (from kss) (1.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from kss) (2023.12.25)\n",
            "Requirement already satisfied: pecab in /usr/local/lib/python3.10/dist-packages (from kss) (1.0.8)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from kss) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (1.25.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (10.0.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (7.4.4)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (2.0.1)\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.5.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n"
          ]
        }
      ],
      "source": [
        "# Package Install\n",
        "# !pip install nltk\n",
        "# !pip install kss\n",
        "# !pip install konlpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1-1 Tokoenization\n",
        "Tokenization : separate sentences as Token(Token is smallest meaningful unit)"
      ],
      "metadata": {
        "id": "uDQtKAUaNCjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')      # Download necessary data\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QETWi7YvMx7x",
        "outputId": "b26da641-ba6b-4050-e16c-c7a981775e9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating Paragraph\n",
        "text = \"The sun sets behind the mountains, painting the sky in shades of orange and pink. A gentle breeze whispers through the leaves, bringing a sense of calm to the bustling city. Under the starlit sky, the world seems to pause, reflecting on the day's events and dreaming of tomorrow.\"\n",
        "\n",
        "print(\"paragraph: \", text)\n",
        "print(\"<Sentences>\")\n",
        "\n",
        "n=0\n",
        "for sent_i in sent_tokenize(text):\n",
        "  print(\"{0}th sentence: {1}\".format(n, sent_i))\n",
        "  n += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqpJkfLtMyD0",
        "outputId": "6c3adeae-d184-4344-8e78-0c2647d16a2a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "paragraph:  The sun sets behind the mountains, painting the sky in shades of orange and pink. A gentle breeze whispers through the leaves, bringing a sense of calm to the bustling city. Under the starlit sky, the world seems to pause, reflecting on the day's events and dreaming of tomorrow.\n",
            "<Sentences>\n",
            "0th sentence: The sun sets behind the mountains, painting the sky in shades of orange and pink.\n",
            "1th sentence: A gentle breeze whispers through the leaves, bringing a sense of calm to the bustling city.\n",
            "2th sentence: Under the starlit sky, the world seems to pause, reflecting on the day's events and dreaming of tomorrow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating Words\n",
        "sentence = \"The sun sets behind the mountains, painting the sky in shades of orange and pink.\"\n",
        "print(\"sentence : \", sentence)\n",
        "print(\"words : \", word_tokenize(sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTtizGU7MyLw",
        "outputId": "42f7b501-7a41-42f1-c6cd-c40b62a20fc5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence :  The sun sets behind the mountains, painting the sky in shades of orange and pink.\n",
            "words :  ['The', 'sun', 'sets', 'behind', 'the', 'mountains', ',', 'painting', 'the', 'sky', 'in', 'shades', 'of', 'orange', 'and', 'pink', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1-2 KSS (Korean Sentence Splitter)"
      ],
      "metadata": {
        "id": "ALp18ywWQpQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KpS_67VmRyKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kss\n",
        "\n",
        "text = \"산 너머로 해가 지면서 하늘은 오렌지와 핑크색으로 물들어 간다. 나뭇잎 사이로 부는 산들바람이 분주한 도시에 평온함을 가져다준다. 별이 빛나는 밤하늘 아래에서 세상은 잠시 멈추어 오늘의 일을 되돌아보고 내일을 꿈꾼다.\"\n",
        "print(\"Paragraph: \", text)\n",
        "print(\"Sentence: \", kss.split_sentences(text))    # Split as sencentences\n",
        "print(\"Sentence: \", kss.split_morphemes(text))    # Split as morphemes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlnN6fOxQkko",
        "outputId": "e679655e-f404-4ef8-d87c-2e5f409baddd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Because there's no supported C++ morpheme analyzer, Kss will take pecab as a backend. :D\n",
            "For your information, Kss also supports mecab backend.\n",
            "We recommend you to install mecab or konlpy.tag.Mecab for faster execution of Kss.\n",
            "Please refer to following web sites for details:\n",
            "- mecab: https://github.com/hyunwoongko/python-mecab-kor\n",
            "- konlpy.tag.Mecab: https://konlpy.org/en/latest/api/konlpy.tag/#mecab-class\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paragraph:  산 너머로 해가 지면서 하늘은 오렌지와 핑크색으로 물들어 간다. 나뭇잎 사이로 부는 산들바람이 분주한 도시에 평온함을 가져다준다. 별이 빛나는 밤하늘 아래에서 세상은 잠시 멈추어 오늘의 일을 되돌아보고 내일을 꿈꾼다.\n",
            "Sentence:  ['산 너머로 해가 지면서 하늘은 오렌지와 핑크색으로 물들어 간다.', '나뭇잎 사이로 부는 산들바람이 분주한 도시에 평온함을 가져다준다.', '별이 빛나는 밤하늘 아래에서 세상은 잠시 멈추어 오늘의 일을 되돌아보고 내일을 꿈꾼다.']\n",
            "Sentence:  [('산', 'NNG'), ('너머', 'NNG'), ('로', 'JKB'), ('해', 'NNG'), ('가', 'JKS'), ('지', 'VV'), ('면서', 'EC'), ('하늘', 'NNG'), ('은', 'JX'), ('오렌지', 'NNG'), ('와', 'JC'), ('핑크', 'NNG'), ('색', 'NNG'), ('으로', 'JKB'), ('물들', 'VV'), ('어', 'EC'), ('간다', 'VX+EF'), ('.', 'SF'), ('나뭇잎', 'NNG'), ('사이', 'NNG'), ('로', 'JKB'), ('부', 'VV'), ('는', 'ETM'), ('산들바람', 'NNG'), ('이', 'JKS'), ('분주', 'NNG'), ('한', 'XSA+ETM'), ('도시', 'NNG'), ('에', 'JKB'), ('평온', 'NNG'), ('함', 'XSA+ETN'), ('을', 'JKO'), ('가져다준다', 'VV+EF'), ('.', 'SF'), ('별', 'NNG'), ('이', 'JKS'), ('빛나', 'VV'), ('는', 'ETM'), ('밤하늘', 'NNG'), ('아래', 'NNG'), ('에서', 'JKB'), ('세상', 'NNG'), ('은', 'JX'), ('잠시', 'MAG'), ('멈추', 'VV'), ('어', 'EC'), ('오늘', 'NNG'), ('의', 'JKG'), ('일', 'NNG'), ('을', 'JKO'), ('되돌아보', 'VV'), ('고', 'EC'), ('내일', 'NNG'), ('을', 'JKO'), ('꿈꾼다', 'VV+EF'), ('.', 'SF')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1-3. POS Tagging\n",
        "POS Tagging: The task of classifying what part of speech each word is"
      ],
      "metadata": {
        "id": "SZgf_7F5Re-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "print()\n",
        "\n",
        "text = \"The sun sets behind the mountains, painting the sky in shades of orange and pink. A gentle breeze whispers through the leaves, bringing a sense of calm to the bustling city. Under the starlit sky, the world seems to pause, reflecting on the day's events and dreaming of tomorrow.\"\n",
        "tokenized_sentence = word_tokenize(text)\n",
        "\n",
        "print(\"Sentence: \", text)\n",
        "print(\"Words: \", tokenized_sentence)\n",
        "print(\"Parts: \", pos_tag(tokenized_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0MzJ483Qkuy",
        "outputId": "66847e2f-cd3f-4778-eb0a-b06df273f0a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence:  The sun sets behind the mountains, painting the sky in shades of orange and pink. A gentle breeze whispers through the leaves, bringing a sense of calm to the bustling city. Under the starlit sky, the world seems to pause, reflecting on the day's events and dreaming of tomorrow.\n",
            "Words:  ['The', 'sun', 'sets', 'behind', 'the', 'mountains', ',', 'painting', 'the', 'sky', 'in', 'shades', 'of', 'orange', 'and', 'pink', '.', 'A', 'gentle', 'breeze', 'whispers', 'through', 'the', 'leaves', ',', 'bringing', 'a', 'sense', 'of', 'calm', 'to', 'the', 'bustling', 'city', '.', 'Under', 'the', 'starlit', 'sky', ',', 'the', 'world', 'seems', 'to', 'pause', ',', 'reflecting', 'on', 'the', 'day', \"'s\", 'events', 'and', 'dreaming', 'of', 'tomorrow', '.']\n",
            "Morphemes:  [('The', 'DT'), ('sun', 'NN'), ('sets', 'NNS'), ('behind', 'IN'), ('the', 'DT'), ('mountains', 'NNS'), (',', ','), ('painting', 'VBG'), ('the', 'DT'), ('sky', 'NN'), ('in', 'IN'), ('shades', 'NNS'), ('of', 'IN'), ('orange', 'NN'), ('and', 'CC'), ('pink', 'NN'), ('.', '.'), ('A', 'DT'), ('gentle', 'JJ'), ('breeze', 'NN'), ('whispers', 'NNS'), ('through', 'IN'), ('the', 'DT'), ('leaves', 'NNS'), (',', ','), ('bringing', 'VBG'), ('a', 'DT'), ('sense', 'NN'), ('of', 'IN'), ('calm', 'NN'), ('to', 'TO'), ('the', 'DT'), ('bustling', 'VBG'), ('city', 'NN'), ('.', '.'), ('Under', 'IN'), ('the', 'DT'), ('starlit', 'NN'), ('sky', 'NN'), (',', ','), ('the', 'DT'), ('world', 'NN'), ('seems', 'VBZ'), ('to', 'TO'), ('pause', 'VB'), (',', ','), ('reflecting', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('day', 'NN'), (\"'s\", 'POS'), ('events', 'NNS'), ('and', 'CC'), ('dreaming', 'NN'), ('of', 'IN'), ('tomorrow', 'NN'), ('.', '.')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "okt = Okt()\n",
        "kkma = Kkma()\n",
        "kor_text = \"산 너머로 해가 지면서 하늘은 오렌지와 핑크색으로 물들어 간다.\"\n",
        "print()\n",
        "\n",
        "print(\"Sentence: \", kor_text)\n",
        "print()\n",
        "print(\"Analyse Morpheme with okt: \", okt.morphs(kor_text))\n",
        "print(\"Parts tagging with okt: \", okt.pos(kor_text))\n",
        "print(\"Extract Noun with okt: \", okt.nouns(kor_text))\n",
        "print()\n",
        "\n",
        "print(\"Analyse Morpheme with kkma: \", kkma.morphs(kor_text))\n",
        "print(\"Parts tagging with kkma: \", kkma.pos(kor_text))\n",
        "print(\"Extract Noun with kkma: \", kkma.nouns(kor_text))\n",
        "print(\"\")"
      ],
      "metadata": {
        "id": "ElXFn5xUMg3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4abba9-16cf-468f-c663-81467b325c3f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence:  산 너머로 해가 지면서 하늘은 오렌지와 핑크색으로 물들어 간다.\n",
            "\n",
            "Analyse Morpheme with okt:  ['산', '너머', '로', '해', '가', '지면', '서', '하늘', '은', '오렌지', '와', '핑크색', '으로', '물들어', '간다', '.']\n",
            "Parts tagging with okt:  [('산', 'Noun'), ('너머', 'Noun'), ('로', 'Josa'), ('해', 'Noun'), ('가', 'Josa'), ('지면', 'Noun'), ('서', 'Josa'), ('하늘', 'Noun'), ('은', 'Josa'), ('오렌지', 'Noun'), ('와', 'Josa'), ('핑크색', 'Noun'), ('으로', 'Josa'), ('물들어', 'Verb'), ('간다', 'Noun'), ('.', 'Punctuation')]\n",
            "Extract Noun with okt:  ['산', '너머', '해', '지면', '하늘', '오렌지', '핑크색', '간다']\n",
            "\n",
            "Analyse Morpheme with kkma:  ['산', '너머', '로', '해', '가', '지', '면서', '하늘', '은', '오렌지', '와', '핑크색', '으로', '물들', '어', '갈', 'ㄴ다', '.']\n",
            "Parts tagging with kkma:  [('산', 'NNG'), ('너머', 'NNG'), ('로', 'JKM'), ('해', 'NNG'), ('가', 'JKS'), ('지', 'VV'), ('면서', 'ECE'), ('하늘', 'NNG'), ('은', 'JX'), ('오렌지', 'NNG'), ('와', 'JKM'), ('핑크색', 'NNG'), ('으로', 'JKM'), ('물들', 'VV'), ('어', 'ECD'), ('갈', 'VV'), ('ㄴ다', 'EFN'), ('.', 'SF')]\n",
            "Extract Noun with kkma:  ['산', '너머', '해', '해가지', '가지', '하늘', '오렌지', '핑크색']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1-4 Lemmatization and Stemming\n",
        "Lemmatization: The base dictionary form of a word (the root of the word)\n"
      ],
      "metadata": {
        "id": "N6tERN9nfZXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "words = ['has','running','walked', 'easily','caring','flies','happier']\n",
        "\n",
        "# Extract Lemmatization\n",
        "print(\"Words: \", words)\n",
        "print(\"Lemmatization : \" , [lemmatizer.lemmatize(word) for word in words])\n",
        "print()\n",
        "\n",
        "# Words:  ['has', 'running', 'walked', 'easily', 'caring', 'flies', 'happier']\n",
        "# Lemmatization :  ['ha', 'running', 'walked', 'easily', 'caring', 'fly', 'happier']\n",
        "\n",
        "# Add Information of Parts\n",
        "print(\"Information for 'has': \", lemmatizer.lemmatize('has', 'v'))\n",
        "print(\"Information for 'running': \", lemmatizer.lemmatize('running', 'v'))\n",
        "print(\"Information for 'walked': \", lemmatizer.lemmatize('walked', 'v'))\n",
        "print(\"Information for 'easily': \", lemmatizer.lemmatize('easily', 'r'))\n",
        "print(\"Information for 'caring': \", lemmatizer.lemmatize('caring', 'v'))\n",
        "print(\"Information for 'flies': \", lemmatizer.lemmatize('flies', 'v'))\n",
        "print(\"Information for 'happier': \", lemmatizer.lemmatize('happier', 'a'))"
      ],
      "metadata": {
        "id": "iQvHPrxFMew_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ddaf11-c4d9-4815-adbd-a6a2ae79d0c9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words:  ['has', 'running', 'walked', 'easily', 'caring', 'flies', 'happier']\n",
            "Lemmatization :  ['ha', 'running', 'walked', 'easily', 'caring', 'fly', 'happier']\n",
            "\n",
            "Information for 'has':  have\n",
            "Information for 'running':  run\n",
            "Information for 'walked':  walk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common POS Tags\n",
        "Part of Speech (POS) tags are used to classify words into their grammatical categories, which helps in understanding their roles within sentences. The following are some common POS tags along with their meanings:\n",
        "\n",
        "#### 1. Noun (N): A person, place, thing, or idea\n",
        "\n",
        "- NN: Singular noun\n",
        "- NNS: Plural nouns\n",
        "- NNP: Proper noun, singular\n",
        "- NNPS: Proper noun, plural\n",
        "\n",
        "#### 2. Pronoun (PRP): A word that takes the place of a noun\n",
        "\n",
        "- PRP: Personal pronoun\n",
        "- PRP$: Possessive pronoun\n",
        "\n",
        "#### 3. Verb (V): Expresses action or being\n",
        "- VB: Base form\n",
        "- VBD: Past tense\n",
        "- VBG: Gerund or present participle\n",
        "- VBN: Past participle\n",
        "- VBP: Present tense, non-3rd person singular\n",
        "- VBZ: Present tense, 3rd person singular\n",
        "\n",
        "#### 4. Adjective (A): Describes a noun\n",
        "- JJ: Adjective\n",
        "- JJR: Comparative adjective\n",
        "- JJS: Superlative adjective\n",
        "\n",
        "#### 5. Adverb (R): Modifies a verb, an adjective, or another adverb.\n",
        "- RB: Adverb\n",
        "- RBR: Comparative adverb\n",
        "- RBS: Superlative adverb\n",
        "\n",
        "#### 6. Preposition (IN): Shows the relationship of a noun or pronoun to another word.\n",
        "#### 7. Conjunction (CC): Connects words, phrases, or clauses.\n",
        "#### 8. Determiner (DT): Introduces a noun.\n",
        "#### 9. Interjection (UH): Expresses emotion.\n",
        "#### 10. Modal (MD): Expresses necessity or possibility.\n"
      ],
      "metadata": {
        "id": "5tHv-jfNjSt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stem: The core part of a word that carries its meaning."
      ],
      "metadata": {
        "id": "ARDAROUpksZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "\n",
        "sentence = \"The sun sets behind the mountains, painting the sky in shades of orange and pink.\"\n",
        "tokenized_sentence = word_tokenize(sentence)[ :16]\n",
        "\n",
        "# Extracting Stem\n",
        "print(\"Words: \", tokenized_sentence)\n",
        "print(\"Extract with Porter: \", [porter.stem(word) for word in tokenized_sentence])\n",
        "print(\"Extract with Lancaster: \", [lancaster.stem(word) for word in tokenized_sentence])\n"
      ],
      "metadata": {
        "id": "bzVPXFrzMkf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bff10248-b7fb-417d-ee46-8403b563b8f5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words:  ['The', 'sun', 'sets', 'behind', 'the', 'mountains', ',', 'painting', 'the', 'sky', 'in', 'shades', 'of', 'orange', 'and', 'pink']\n",
            "Extract with Porter:  ['the', 'sun', 'set', 'behind', 'the', 'mountain', ',', 'paint', 'the', 'sky', 'in', 'shade', 'of', 'orang', 'and', 'pink']\n",
            "Extract with Lancaster:  ['the', 'sun', 'set', 'behind', 'the', 'mountain', ',', 'paint', 'the', 'sky', 'in', 'shad', 'of', 'orang', 'and', 'pink']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-5 Stop word\n",
        "A word that carries little meaning."
      ],
      "metadata": {
        "id": "gOLCQ3N8mPMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "print()\n",
        "\n",
        "stop_words_list = stopwords.words('english')\n",
        "print(\"the number of nltk stopwords: \", len(stop_words_list))\n",
        "print(\"Example of stopwords: \", stop_words_list[:5])"
      ],
      "metadata": {
        "id": "H5b6KaQrMlSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a0956b-308e-4f43-c598-9322630d7648"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "the number of nltk stopwords:  179\n",
            "Example of stopwords:  ['i', 'me', 'my', 'myself', 'we']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting manuelly stopwords\n",
        "example = \"이 문장에서 불용어를 제외하면 무엇이 남을까요?\"\n",
        "stop_words = \"이 에서 를 하면\"\n",
        "\n",
        "# Remove stop_words\n",
        "stop_words = stop_words.split(' ')\n",
        "word_tokens = okt.morphs(example)\n",
        "\n",
        "result = [word for word in word_tokens if not word in stop_words]\n",
        "\n",
        "print(\"before: \", word_tokens)\n",
        "print(\"after: \", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGtLnS9km_a5",
        "outputId": "c9eb1e0d-9591-4b85-ad61-951385c01b6e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before:  ['이', '문장', '에서', '불', '용어', '를', '제외', '하면', '무엇', '이', '남을까요', '?']\n",
            "after:  ['문장', '불', '용어', '제외', '무엇', '남을까요', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-6. Regular Expressions"
      ],
      "metadata": {
        "id": "0IMZB0baoeoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aY5qx3_9nAaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# a random character\n",
        "r_1 = re.compile(\"a.c\")\n",
        "print(\"abc: \", r_1.search(\"abc\"))     # any only one character(b) between a and c, it should be ok\n",
        "print(\"azc: \", r_1.search(\"azc\"))     # any only one character(z) between a and c, it should be ok\n",
        "print(\"abbc: \", r_1.search(\"abbc\"))   # any two character between a and c, it should be None\n",
        "print(\"acd: \", r_1.search(\"acd\"))     # others, it should be None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4iZJPW3m_iM",
        "outputId": "653c42a5-9de8-4be8-86e4-04fc5b4de4fd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abc:  <re.Match object; span=(0, 3), match='abc'>\n",
            "azc:  <re.Match object; span=(0, 3), match='azc'>\n",
            "abbc:  None\n",
            "acd:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If character exists or not\n",
        "r_2 = re.compile(\"ab?c\")\n",
        "print(\"abc: \", r_2.search(\"abc\"))     # any only one character(b) between a and c , it should be ok\n",
        "print(\"ac: \", r_2.search(\"ac\"))       # no character exists, it should be ok\n",
        "print(\"ab: \", r_2.search(\"ab\"))       # others, it should be None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9irQy4Zm_kd",
        "outputId": "04f279db-6ff1-444c-b4ce-a3f98abeeb56"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abc:  <re.Match object; span=(0, 3), match='abc'>\n",
            "ac:  <re.Match object; span=(0, 2), match='ac'>\n",
            "ab:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If more than 0 character exists\n",
        "r_3 = re.compile(\"ab*c\")\n",
        "print(\"ac: \", r_3.search(\"ac\"))       # no character exists, it should be ok\n",
        "print(\"abc: \", r_3.search(\"abc\"))     # any only one character(b) between a and c , it should be ok\n",
        "print(\"ab: \", r_3.search(\"ab\"))       # others, it should be None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxWsuVdhm_mr",
        "outputId": "c0069d68-06a2-4cee-c72f-d4f2bd3053c9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ac:  <re.Match object; span=(0, 2), match='ac'>\n",
            "abc:  <re.Match object; span=(0, 3), match='abc'>\n",
            "ab:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If more than 1 character exists\n",
        "r_4 = re.compile(\"ab+c\")\n",
        "print(\"ac: \", r_4.search(\"ac\"))       # no character exists, it should be None\n",
        "print(\"abc: \", r_4.search(\"abc\"))     # any only one character(b) between a and c , it should be ok\n",
        "print(\"ab: \", r_4.search(\"ab\"))       # others, it should be None"
      ],
      "metadata": {
        "id": "52JthSBJMlnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d92e5d-9d76-43fc-ff6c-75de2e2d5569"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ac:  None\n",
            "abc:  <re.Match object; span=(0, 3), match='abc'>\n",
            "ab:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with a specific string\n",
        "r_5 = re.compile(\"^a\")\n",
        "print(\"a: \", r_5.search(\"a\"))         # start with 'a', it should be ok\n",
        "print(\"abc: \", r_5.search(\"abc\"))     # start with 'a', it should be ok\n",
        "print(\"ba: \", r_5.search(\"ba\"))       # not start with 'a'. it should be None"
      ],
      "metadata": {
        "id": "Gq9sRz_NMl2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff09d53-a7af-444a-e67c-9e13274bfb20"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:  <re.Match object; span=(0, 1), match='a'>\n",
            "abc:  <re.Match object; span=(0, 1), match='a'>\n",
            "ba:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat a certain number of times\n",
        "r_6 = re.compile(\"ab{2}c\")\n",
        "print(\"a: \", r_6.search(\"abc\"))         # it should be None\n",
        "print(\"abbc: \", r_6.search(\"abbc\"))     # repeat b twice, it should be ok\n",
        "print(\"ba: \", r_6.search(\"babbc\"))      # it should be None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mKLOBUXyb9h",
        "outputId": "e30edb8c-9808-41ab-cdec-2dbbc3f60518"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:  None\n",
            "abbc:  <re.Match object; span=(0, 4), match='abbc'>\n",
            "ba:  <re.Match object; span=(1, 5), match='abbc'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat a certain range of times\n",
        "r_7 = re.compile(\"ab{2,3}c\")\n",
        "print(\"abc: \", r_7.search(\"abc\"))         # only one 'b', it should be None\n",
        "print(\"abbc: \", r_7.search(\"abbc\"))     # repeat b twice, it should be ok\n",
        "print(\"abbbc: \", r_7.search(\"abbbc\"))   # repeat b three times, it should be ok\n",
        "print(\"abbbbc: \", r_7.search(\"abbbbc\"))   # repeat b four times, it should be None\n",
        "print()\n",
        "\n",
        "r_7_a = re.compile(\"ab{2,}c\")\n",
        "print(\"abc: \", r_7_a.search(\"abc\"))         # only one 'b', it should be None\n",
        "print(\"abbc: \", r_7_a.search(\"abbc\"))     # repeat b twice, it should be ok\n",
        "print(\"abbbc: \", r_7_a.search(\"abbbc\"))   # repeat b three times, it should be ok\n",
        "print(\"abbbbc: \", r_7_a.search(\"abbbbc\"))   # repeat b four times, it should be ok\n",
        "print()\n",
        "\n",
        "r_7_b = re.compile(\"ab{,2}c\")\n",
        "print(\"abc: \", r_7_b.search(\"abc\"))         # only one 'b', it should be ok\n",
        "print(\"abbc: \", r_7_b.search(\"abbc\"))     # repeat b twice, it should be ok\n",
        "print(\"abbbc: \", r_7_b.search(\"abbbc\"))   # repeat b three times, it should be None\n",
        "print(\"abbbbc: \", r_7_b.search(\"abbbbc\"))   # repeat b four times, it should be None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhF9epDpycGN",
        "outputId": "c9141f89-4903-4ad3-d204-262886abdf09"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:  None\n",
            "abbc:  <re.Match object; span=(0, 4), match='abbc'>\n",
            "abbbc:  <re.Match object; span=(0, 5), match='abbbc'>\n",
            "abbbbc:  None\n",
            "\n",
            "a:  None\n",
            "abbc:  <re.Match object; span=(0, 4), match='abbc'>\n",
            "abbbc:  <re.Match object; span=(0, 5), match='abbbc'>\n",
            "abbbbc:  <re.Match object; span=(0, 6), match='abbbbc'>\n",
            "\n",
            "a:  <re.Match object; span=(0, 3), match='abc'>\n",
            "abbc:  <re.Match object; span=(0, 4), match='abbc'>\n",
            "abbbc:  None\n",
            "abbbbc:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Include a specific string\n",
        "r_8 = re.compile(\"[abc]\")   # a or b or c\n",
        "print(\"aim: \", r_8.search(\"aim\"))         # there exists 'a', it should be ok\n",
        "print(\"cat: \", r_8.search(\"cat\"))         # it has 'a' and 'c', it should be ok\n",
        "print(\"banana: \", r_8.search(\"banana\"))   # it has 'b' and 'a', it should be ok\n",
        "print(\"run: \", r_8.search(\"run\"))         # no 'a', 'b' or 'c', it should be None\n",
        "print()\n",
        "\n",
        "# Include specific strings with a certain ranges\n",
        "r_8_a = re.compile(\"[a-y]\")   # a to y\n",
        "print(\"aim: \", r_8_a.search(\"aim\"))         # it should be ok\n",
        "print(\"z: \", r_8_a.search(\"z\"))             # it has only 'z', it should be None\n",
        "print(\"yz: \", r_8_a.search(\"yz\"))           # it has 'y', it should be ok\n",
        "print(\"!: \", r_8_a.search(\"!\"))             # it has no character, it should be None\n",
        "print(\"run!: \", r_8_a.search(\"run!\"))       # it has character, it should be ok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL0Zt3rMycIt",
        "outputId": "2e87dc3b-aa42-4fab-fdaf-9dfebdd94f8e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aim:  <re.Match object; span=(0, 1), match='a'>\n",
            "cat:  <re.Match object; span=(0, 1), match='c'>\n",
            "banana:  <re.Match object; span=(0, 1), match='b'>\n",
            "run:  None\n",
            "\n",
            "aim:  <re.Match object; span=(0, 1), match='a'>\n",
            "z:  None\n",
            "yz:  <re.Match object; span=(0, 1), match='y'>\n",
            "!:  None\n",
            "run!:  <re.Match object; span=(0, 1), match='r'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclude specific strings\n",
        "r_9 = re.compile(\"[^abc]\")   # exclude a, b and c\n",
        "print(\"abc: \", r_9.search(\"abc\"))         # there exists only 'a', 'b' and 'c', it should be None\n",
        "print(\"ca: \", r_9.search(\"ca\"))           # it has 'a' and 'c', it should be None\n",
        "print(\"banana: \", r_9.search(\"banana\"))   # it has 'n', it should be ok\n",
        "print(\"run: \", r_9.search(\"run\"))         # no 'a', 'b' or 'c', it should be ok\n",
        "print()\n",
        "\n",
        "# Exclude specific strings with a certain range\n",
        "r_9_a = re.compile(\"[^a-y]\")   # exclude a to y\n",
        "print(\"abc: \", r_9_a.search(\"abc\"))         # there exists only 'a', 'b' and 'c', it should be None\n",
        "print(\"y: \", r_9_a.search(\"y\"))             # it has 'a' and 'y', it should be None\n",
        "print(\"z: \", r_9_a.search(\"z\"))             # it has no 'a' to 'y', it should be ok\n",
        "print(\"yz: \", r_9_a.search(\"yz\"))           # it has 'z', it should be ok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejHDN5s2ycLp",
        "outputId": "273a610f-15e0-478c-f075-1010ccc8c15f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abc:  None\n",
            "ca:  None\n",
            "banana:  <re.Match object; span=(2, 3), match='n'>\n",
            "run:  <re.Match object; span=(0, 1), match='r'>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Include one of a specific string\n",
        "r_10 = re.compile(\"[a|ox]\")   # Include a or ox\n",
        "print(\"a: \", r_10.search(\"a\"))              # there exists only 'a', it should be ok\n",
        "print(\"ox: \", r_10.search(\"ox\"))            # there exsits only 'ox', it should be ok\n",
        "print(\"aox: \", r_10.search(\"aox\"))          # it should be ok\n",
        "print(\"oxygen: \", r_10.search(\"oxygen\"))    # it has 'ox', it should be ok\n",
        "print(\"run: \", r_10.search(\"run\"))          # it has neither 'a' nor 'ox', it should be None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFz6j5zcycQ7",
        "outputId": "23d571e5-92f1-4f4a-9d9f-0f3832621c8b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:  <re.Match object; span=(0, 1), match='a'>\n",
            "ox:  <re.Match object; span=(0, 1), match='o'>\n",
            "aox:  <re.Match object; span=(0, 1), match='a'>\n",
            "oxygen:  <re.Match object; span=(0, 1), match='o'>\n",
            "run:  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jIv1KkIA3Ami"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kG5PVgo73Aon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l_kFj7-83Aq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-_X_bx-L3AtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jqaTi5q_3AvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJGY0uZO3AxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MSMKBSSJ3Azd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "efiBa7Nm3A1i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}